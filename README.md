# RAG Policy Assistant

## ğŸ“Œ Objective

This project implements a small **Retrieval-Augmented Generation (RAG)** system to answer questions about company policy documents.

The goal is to demonstrate:

* Prompt engineering and iteration
* Grounded LLM responses using retrieved context
* Hallucination avoidance
* Clear evaluation and reasoning

The system answers only from the provided policy documents and gracefully handles missing or out-of-scope queries.

---

## ğŸ§© Problem Overview

Given a set of company policy documents (e.g., Refund, Cancellation, Shipping, Payment), the system:

* Retrieves relevant policy content using semantic search
* Passes retrieved context to a local LLM
* Produces accurate, factual, non-hallucinated answers
* Explicitly refuses opinions, paraphrasing, and conversation-history questions

---

## ğŸ—ï¸ Architecture Overview

```
User Question
      â†“
FastAPI Backend
      â†“
Embedding Model (Sentence Transformers)
      â†“
Vector Store (ChromaDB)
      â†“
Top-K Relevant Chunks
      â†“
Local LLM (Ollama)
      â†“
Final Answer
```

The system is **stateless** and does not retain conversation history.

---

## ğŸ› ï¸ Tech Stack

* **Language:** Python
* **Backend:** FastAPI
* **LLM:** Ollama (local, open-source)
* **Embeddings:** all-MiniLM-L6-v2
* **Vector Store:** ChromaDB
* **Frontend:** Minimal chat-style UI (HTML/CSS/JS)
* **Deployment:** Local server exposed via ngrok (demo only)

---

## ğŸ“ Project Structure

```
rag-policy-assistant/
â”‚
â”œâ”€â”€ app.py                # FastAPI application
â”œâ”€â”€ main.py               # RAG pipeline logic
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ policies/         # Policy documents (.txt)
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ prompt_v1_initial.txt
â”‚   â””â”€â”€ prompt_v2_improved.txt
â”‚
â”œâ”€â”€ responses/
â”‚   â”œâ”€â”€ responses_v1_initial.txt
â”‚   â””â”€â”€ responses_v2_improved.txt
â”‚
â”œâ”€â”€ chroma_db/            # Vector DB persistence
â”‚
â””â”€â”€ templates/
    â””â”€â”€ index.html        # Chat UI
```

---

## ğŸ“„ Data Preparation & Chunking

### Chunking Strategy

* Chunk size: **500 characters**
* Chunk overlap: **100 characters**

### Rationale

* Policy documents contain short, self-contained rules
* 500 characters preserves semantic completeness
* Overlap prevents boundary information loss
* Smaller chunks improve retrieval precision

Each chunk is augmented with its policy type to improve retrieval clarity.

---

## ğŸ”— RAG Pipeline

1. Load policy documents (.txt)
2. Chunk documents using recursive splitting
3. Generate embeddings using Sentence Transformers
4. Store embeddings in ChromaDB
5. Retrieve top-k relevant chunks per query
6. Inject retrieved context into a structured prompt
7. Generate response using a local LLM (Ollama)

---

## âœï¸ Prompt Engineering

Prompt engineering was iterated to reduce hallucinations and enforce strict grounding.

### Prompt Versions

**Version 1 â€“ Initial**

* Allowed opinions
* Inconsistent policy listing
* Occasional hallucinations

**Version 2 â€“ Improved**

* Context-only answers
* Deterministic refusals
* No conversation memory
* No paraphrasing or opinions

---

## ğŸ§ª Evaluation

### Sample Evaluation Questions

| Question                               | Expected Behavior      |
| -------------------------------------- | ---------------------- |
| What policies do you know about?       | List all policies      |
| Are digital products refundable?       | Answer from policy     |
| Can I cancel after shipping?           | Partial factual answer |
| What do you think about refund policy? | Refusal                |
| What was my previous question?         | Refusal                |
| Who is the CEO?                        | â€œI donâ€™t knowâ€         |

### Results

| Criterion               | Result        |
| ----------------------- | ------------- |
| Accuracy                | High          |
| Hallucination Avoidance | Strong        |
| Answer Clarity          | Clear         |
| Edge Case Handling      | Deterministic |

---

## ğŸš¨ Edge Case Handling

The system explicitly handles:

* **No relevant documents**
  â†’ â€œI donâ€™t know based on the provided documents.â€

* **Opinion / feedback questions**
  â†’ Refused deterministically

* **Paraphrasing requests**
  â†’ Refused

* **Conversation-history queries**
  â†’ Refused (stateless system)

This behavior is enforced via prompt design, not hard-coded logic.

---

## ğŸŒ Running the Project

### 1ï¸âƒ£ Install Dependencies

```
pip install -r requirements.txt
```

### 2ï¸âƒ£ Start Ollama

```
ollama run qwen2.5:0.5b
```

### 3ï¸âƒ£ Start Server

```
uvicorn app:app --host 0.0.0.0 --port 8000
```

### 4ï¸âƒ£ Access UI

```
http://127.0.0.1:8000
```

API Docs:

```
http://127.0.0.1:8000/docs
```

---

## âš–ï¸ Trade-offs & Future Improvements

### Trade-offs

* Lightweight embeddings â†’ Faster, lower recall
* No reranking â†’ Simpler pipeline
* Local LLM â†’ No external API dependency

### Future Improvements

* Cross-encoder reranking
* Citation highlighting
* Automated evaluation
* Cloud deployment
* JSON schema validation

---
# RAG-policy-Assistant
